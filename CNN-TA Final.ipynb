{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yfinance as yf\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import talib\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import time\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.metrics import *\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"> <center> FUNCTIONS </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "\n",
    "def set_random_seed():\n",
    "    tf.keras.utils.set_random_seed(SEED)\n",
    "\n",
    "\n",
    "def HMA(df: pd.DataFrame, timeperiod: int = 14) -> float:\n",
    "    \"\"\"\n",
    "    Hull Moving Average.\n",
    "    Formula:\n",
    "    HMA = WMA(2*WMA(n/2) - WMA(n)), sqrt(n)\n",
    "    \"\"\"\n",
    "    hma = talib.WMA(\n",
    "        2 * talib.WMA(df, int(timeperiod / 2)) - talib.WMA(df, timeperiod),\n",
    "        int(np.sqrt(timeperiod)),\n",
    "    )\n",
    "    return hma\n",
    "\n",
    "\n",
    "def money_flow_volume_series(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculates money flow series\n",
    "    \"\"\"\n",
    "    mfv = (\n",
    "        df[\"Volume\"]\n",
    "        * (2 * df[\"Close\"] - df[\"High\"] - df[\"Low\"])\n",
    "        / (df[\"High\"] - df[\"Low\"])\n",
    "    )\n",
    "    return mfv\n",
    "\n",
    "\n",
    "def money_flow_volume(df: pd.DataFrame, timeperiod: int = 20) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculates money flow volume, or q_t in our formula\n",
    "    \"\"\"\n",
    "    return money_flow_volume_series(df).rolling(timeperiod).sum()\n",
    "\n",
    "\n",
    "def CMF(df: pd.DataFrame, timeperiod: int = 20) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculates the Chaikin money flow\n",
    "    \"\"\"\n",
    "    return money_flow_volume(df, timeperiod) / df[\"Volume\"].rolling(timeperiod).sum()\n",
    "\n",
    "\n",
    "def pltcolor(lst: list) -> list:\n",
    "    cols = []\n",
    "    for i in range(lst.shape[0]):\n",
    "        if lst.iloc[i] == 1:\n",
    "            cols.append(\"green\")\n",
    "        elif lst.iloc[i] == 2:\n",
    "            cols.append(\"red\")\n",
    "    return cols\n",
    "\n",
    "\n",
    "def trendNormalizePrices(prices: pd.DataFrame) -> None:\n",
    "    df = prices.copy()\n",
    "    df[\"rowNumber\"] = list(range(len(df)))\n",
    "    df[\"TN_Open\"] = list(range(len(df)))\n",
    "    df[\"TN_High\"] = list(range(len(df)))\n",
    "    df[\"TN_Low\"] = list(range(len(df)))\n",
    "    df[\"TN_Close\"] = list(range(len(df)))\n",
    "    for i in range(29, len(df)):\n",
    "        model = LinearRegression()\n",
    "        model.fit(\n",
    "            np.array(df[\"rowNumber\"].iloc[i - 29 : i + 1]).reshape(-1, 1),\n",
    "            np.array(df[\"Close\"].iloc[i - 29 : i + 1]),\n",
    "        )\n",
    "        prediction = model.predict(np.array([df[\"rowNumber\"].iloc[i]]).reshape(-1, 1))\n",
    "        df.iloc[i, df.columns.get_loc(\"TN_Open\")] = df[\"Open\"].iloc[i] - prediction\n",
    "        df.iloc[i, df.columns.get_loc(\"TN_High\")] = df[\"High\"].iloc[i] - prediction\n",
    "        df.iloc[i, df.columns.get_loc(\"TN_Low\")] = df[\"Low\"].iloc[i] - prediction\n",
    "        df.iloc[i, df.columns.get_loc(\"TN_Close\")] = df[\"Close\"].iloc[i] - prediction\n",
    "    df[\"Open\"] = df[\"TN_Open\"]\n",
    "    df[\"High\"] = df[\"TN_High\"]\n",
    "    df[\"Low\"] = df[\"TN_Low\"]\n",
    "    df[\"Close\"] = df[\"TN_Close\"]\n",
    "    df = df.drop(index=df.index[:30], axis=0)\n",
    "    df = df.drop(\n",
    "        columns=[\"TN_Open\", \"TN_High\", \"TN_Low\", \"TN_Close\", \"rowNumber\"], axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_labels(prices: pd.DataFrame) -> None:\n",
    "    df = prices.copy()\n",
    "    df[\"Label\"] = [0] * df.shape[0]\n",
    "    for i in range(df.shape[0] - 10):\n",
    "        s = set(df[\"Close\"].iloc[i : i + 11])\n",
    "        minPrice = sorted(s)[0]\n",
    "        maxPrice = sorted(s)[-1]\n",
    "        for j in range(i, i + 11):\n",
    "            if df[\"Close\"].iloc[j] == minPrice and (j - i) == 5:\n",
    "                df.iloc[j, df.columns.get_loc(\"Label\")] = 1\n",
    "            elif df[\"Close\"].iloc[j] == maxPrice and (j - i) == 5:\n",
    "                df.iloc[j, df.columns.get_loc(\"Label\")] = 2\n",
    "    return df.iloc[6:-6]\n",
    "\n",
    "\n",
    "def reverse_one_hot(predictions: np.array) -> np.array:\n",
    "    return np.argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "def one_hot(predictions: np.array) -> np.array:\n",
    "    predictions_one_hot = []\n",
    "    for i in predictions:\n",
    "        prediction = [0, 0, 0]\n",
    "        prediction[int(i)] = 1\n",
    "        predictions_one_hot.append(prediction)\n",
    "    return np.array(predictions_one_hot)\n",
    "\n",
    "\n",
    "def number_null_and_nan(df: pd.DataFrame) -> int:\n",
    "    na = pd.isna(df).sum().sum()\n",
    "    null = df.isnull().sum().sum()\n",
    "    return na + null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"> <center> DATA PREPROCESSING </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = yf.download(\n",
    "    \"SPY\",\n",
    "    start=\"2009-09-20\",\n",
    "    end=\"2023-01-01\",\n",
    "    interval=\"1d\",\n",
    "    progress=False,\n",
    "    auto_adjust=True,\n",
    ")\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"SPY Price 2010-2022\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.plot(prices[[\"Close\"]].iloc[150:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> Trend Normalize and Visualize </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-11-02 00:00:00-05:00</th>\n",
       "      <td>-2.497194</td>\n",
       "      <td>-1.503497</td>\n",
       "      <td>-3.312328</td>\n",
       "      <td>-2.349691</td>\n",
       "      <td>254222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-03 00:00:00-05:00</th>\n",
       "      <td>-2.646066</td>\n",
       "      <td>-1.823161</td>\n",
       "      <td>-2.801328</td>\n",
       "      <td>-1.939610</td>\n",
       "      <td>228362600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-04 00:00:00-05:00</th>\n",
       "      <td>-1.110670</td>\n",
       "      <td>-0.474087</td>\n",
       "      <td>-1.778307</td>\n",
       "      <td>-1.568703</td>\n",
       "      <td>247996700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-05 00:00:00-05:00</th>\n",
       "      <td>-0.968826</td>\n",
       "      <td>-0.021718</td>\n",
       "      <td>-1.139617</td>\n",
       "      <td>-0.045007</td>\n",
       "      <td>180015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-06 00:00:00-05:00</th>\n",
       "      <td>-0.466977</td>\n",
       "      <td>0.418029</td>\n",
       "      <td>-0.630004</td>\n",
       "      <td>0.208419</td>\n",
       "      <td>170954100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23 00:00:00-05:00</th>\n",
       "      <td>-7.306054</td>\n",
       "      <td>-3.896050</td>\n",
       "      <td>-8.926049</td>\n",
       "      <td>-4.046044</td>\n",
       "      <td>59857300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27 00:00:00-05:00</th>\n",
       "      <td>-2.835277</td>\n",
       "      <td>-2.475292</td>\n",
       "      <td>-5.975292</td>\n",
       "      <td>-4.225292</td>\n",
       "      <td>51638200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 00:00:00-05:00</th>\n",
       "      <td>-2.236787</td>\n",
       "      <td>-0.176759</td>\n",
       "      <td>-7.146761</td>\n",
       "      <td>-6.906770</td>\n",
       "      <td>70911500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29 00:00:00-05:00</th>\n",
       "      <td>-3.069598</td>\n",
       "      <td>1.650403</td>\n",
       "      <td>-3.619617</td>\n",
       "      <td>0.740399</td>\n",
       "      <td>66970900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30 00:00:00-05:00</th>\n",
       "      <td>-0.947872</td>\n",
       "      <td>0.992100</td>\n",
       "      <td>-3.157894</td>\n",
       "      <td>0.842106</td>\n",
       "      <td>83975100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3314 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Open      High       Low     Close     Volume\n",
       "Date                                                                        \n",
       "2009-11-02 00:00:00-05:00 -2.497194 -1.503497 -3.312328 -2.349691  254222900\n",
       "2009-11-03 00:00:00-05:00 -2.646066 -1.823161 -2.801328 -1.939610  228362600\n",
       "2009-11-04 00:00:00-05:00 -1.110670 -0.474087 -1.778307 -1.568703  247996700\n",
       "2009-11-05 00:00:00-05:00 -0.968826 -0.021718 -1.139617 -0.045007  180015300\n",
       "2009-11-06 00:00:00-05:00 -0.466977  0.418029 -0.630004  0.208419  170954100\n",
       "...                             ...       ...       ...       ...        ...\n",
       "2022-12-23 00:00:00-05:00 -7.306054 -3.896050 -8.926049 -4.046044   59857300\n",
       "2022-12-27 00:00:00-05:00 -2.835277 -2.475292 -5.975292 -4.225292   51638200\n",
       "2022-12-28 00:00:00-05:00 -2.236787 -0.176759 -7.146761 -6.906770   70911500\n",
       "2022-12-29 00:00:00-05:00 -3.069598  1.650403 -3.619617  0.740399   66970900\n",
       "2022-12-30 00:00:00-05:00 -0.947872  0.992100 -3.157894  0.842106   83975100\n",
       "\n",
       "[3314 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn_prices = trendNormalizePrices(prices)\n",
    "tn_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Trend Normalized SPY Price 2010-2022\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.plot(tn_prices[[\"Close\"]].iloc[150:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> Adding Technical Indicators </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_and_indicators = tn_prices.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7,30):\n",
    "    prices_and_indicators[f\"RSI-{i}\"] = talib.RSI(prices_and_indicators[\"Close\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"WILLR-{i}\"] = talib.WILLR(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"],prices_and_indicators[\"Close\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"STOCH-{i}\"] = talib.STOCH(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"],prices_and_indicators[\"Close\"], fastk_period=i+7, slowk_period=i-4)[0]\n",
    "    prices_and_indicators[f\"STOCHF-{i}\"] = talib.STOCHF(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"],prices_and_indicators[\"Close\"], fastk_period=i-2, fastd_period=i-4)[0]\n",
    "    prices_and_indicators[f\"SMA-{i}\"] = talib.SMA(prices_and_indicators[\"Close\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"EMA-{i}\"] = talib.EMA(prices_and_indicators[\"Close\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"WMA-{i}\"] = talib.WMA(prices_and_indicators[\"Close\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"HMA-{i}\"] = HMA(prices_and_indicators[\"Close\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"TEMA-{i}\"] = talib.TEMA(prices_and_indicators[\"Close\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"PPO-{i}\"] = talib.PPO(prices_and_indicators[\"Close\"], fastperiod=i, slowperiod=i+14)\n",
    "    prices_and_indicators[f\"ROC-{i}\"] = talib.ROC(prices_and_indicators[\"Close\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"CMO-{i}\"] = talib.CMO(prices_and_indicators[\"Close\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"MACD-{i}\"] = talib.MACD(prices_and_indicators[\"Close\"], fastperiod=i, slowperiod=i+14)[0]\n",
    "    prices_and_indicators[f\"MAMA-{i}\"] = talib.MAMA(prices_and_indicators[\"Close\"], fastlimit=1/i, slowlimit=1/(i+14))[0]\n",
    "    prices_and_indicators[f\"STOCHRSI-{i}\"] = talib.STOCHRSI(prices_and_indicators[\"Close\"], timeperiod=i)[0]\n",
    "    prices_and_indicators[f\"DX-{i}\"] = talib.DX(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"],prices_and_indicators[\"Close\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"ADXR-{i}\"] = talib.ADXR(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"],prices_and_indicators[\"Close\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"CCI-{i}\"] = talib.CCI(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"],prices_and_indicators[\"Close\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"PLUS_DI-{i}\"] = talib.PLUS_DI(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"],prices_and_indicators[\"Close\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"MINUS_DI-{i}\"] = talib.MINUS_DI(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"],prices_and_indicators[\"Close\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"ATR-{i}\"] = talib.ATR(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"],prices_and_indicators[\"Close\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"SAR-{i}\"] = talib.SAR(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"], maximum = 1/i)\n",
    "    prices_and_indicators[f\"PLUS_DM-{i}\"] = talib.PLUS_DM(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"AROONOSC-{i}\"] = talib.AROONOSC(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"MIDPRICE-{i}\"] = talib.MIDPRICE(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"MFI-{i}\"] = talib.MFI(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"],prices_and_indicators[\"Close\"],prices_and_indicators[\"Volume\"], timeperiod = i)\n",
    "    prices_and_indicators[f\"ADOSC-{i}\"] = talib.ADOSC(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"],prices_and_indicators[\"Close\"],prices_and_indicators[\"Volume\"], fastperiod=i-4, slowperiod=i+3)\n",
    "    prices_and_indicators[f\"BBANDS-{i}\"] = talib.BBANDS(prices_and_indicators[\"Close\"], timeperiod = i)[1]\n",
    "    prices_and_indicators[f\"CMF-{i}\"] = CMF(prices_and_indicators, timeperiod = i)\n",
    "prices_and_indicators[\"BOP\"] = talib.BOP(prices_and_indicators[\"Open\"],prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"],prices_and_indicators[\"Close\"])\n",
    "prices_and_indicators[\"TRANGE\"] = talib.TRANGE(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"],prices_and_indicators[\"Close\"])    \n",
    "prices_and_indicators[\"SAREXT\"] = talib.SAREXT(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"])\n",
    "prices_and_indicators[\"AD\"] = talib.AD(prices_and_indicators[\"High\"],prices_and_indicators[\"Low\"],prices_and_indicators[\"Close\"],prices_and_indicators[\"Volume\"])\n",
    "prices_and_indicators[\"OBV\"] = talib.OBV(prices_and_indicators[\"Close\"],prices_and_indicators[\"Volume\"])\n",
    "prices_and_indicators.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_and_indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> Data Labeling </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_and_indicators_with_label = create_labels(prices_and_indicators)\n",
    "prices_and_indicators_with_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_and_indicators_with_label[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20, 10\n",
    "plt.figure(figsize=(50, 30))\n",
    "prices_and_indicators_with_label[[\"Close\"]].plot(kind=\"line\", stacked=False,linewidth=1)\n",
    "buy_and_sell_preds = prices_and_indicators_with_label.query('Label != 0')\n",
    "plt.scatter(x = buy_and_sell_preds.index, y = buy_and_sell_preds.Close, s=5, c=pltcolor(buy_and_sell_preds.Label))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_with_label = create_labels(prices)\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "plt.figure(figsize=(50, 30))\n",
    "prices_with_label[[\"Close\"]].plot(kind=\"line\", stacked=False,linewidth=1)\n",
    "buy_and_sell_preds = prices_with_label.query('Label != 0')\n",
    "plt.scatter(x = buy_and_sell_preds.index, y = buy_and_sell_preds.Close, s=5, c=pltcolor(buy_and_sell_preds.Label))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> Creating Train & Test Data </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_and_indicators_with_label.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = []\n",
    "\n",
    "for i in range(5, 13):\n",
    "    train = prices_and_indicators_with_label.loc[ (prices_and_indicators_with_label.index >= f\"{2010+i-5}\") & (prices_and_indicators_with_label.index <= f\"{2010+i}\") ]\n",
    "    test = prices_and_indicators_with_label.loc[ (prices_and_indicators_with_label.index >= f\"{2010+i}\") & (prices_and_indicators_with_label.index <= f\"{2010+i+1}\") ]\n",
    "    datas.append([train, test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> Feature Selection </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(datas)):\n",
    "    selected_feature_count = 30\n",
    "    select = SelectKBest(score_func=f_classif, k = selected_feature_count)\n",
    "    fitted = select.fit(datas[i][0].iloc[:,:-1], datas[i][0].iloc[:,-1])\n",
    "    train_features = fitted.transform(datas[i][0].iloc[:,:-1])\n",
    "    test_features = fitted.transform(datas[i][1].iloc[:,:-1])\n",
    "    \n",
    "    selected_features_boolean = select.get_support()\n",
    "    features = list(datas[i][1].columns[:-1])\n",
    "    selected_features = []\n",
    "    for j in range(len(features)):\n",
    "        if selected_features_boolean[j]:\n",
    "            selected_features.append(features[j])\n",
    "    train_label = datas[i][0].Label\n",
    "    test_label = datas[i][1].Label\n",
    "    \n",
    "    datas[i][0] = pd.DataFrame(data=train_features.astype('float32'), columns=selected_features, index=datas[i][0].index)\n",
    "    datas[i][0][\"Label\"] = train_label\n",
    "    datas[i][1] = pd.DataFrame(data=test_features.astype('float32'), columns=selected_features, index=datas[i][1].index)\n",
    "    datas[i][1][\"Label\"] = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(datas)):\n",
    "    abs_scaler = MaxAbsScaler()\n",
    "    abs_scaler.fit(datas[i][0])\n",
    "    scaled_train = abs_scaler.transform(datas[i][0])\n",
    "    scaled_test = abs_scaler.transform(datas[i][1])\n",
    "    datas[i][0] = pd.DataFrame(data=scaled_train, columns=datas[i][0].columns, index=datas[i][0].index)\n",
    "    datas[i][0][\"Label\"] = datas[i][0][\"Label\"] * 2\n",
    "    datas[i][1] = pd.DataFrame(data=scaled_test, columns=datas[i][1].columns, index=datas[i][1].index)\n",
    "    datas[i][1][\"Label\"] = datas[i][1][\"Label\"] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> Controling Null Values </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_na_count = 0\n",
    "for data in datas:\n",
    "    total_na_count += number_null_and_nan(data[0])\n",
    "    total_na_count += number_null_and_nan(data[1])\n",
    "print(f\"Total null and nan values = {total_na_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"> <center> MODEL INITIALIZATIONS </center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> MLP </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_MLP(trial=None, activation_func=\"swish\", dropout_rate = 0.2, optimizer_algo = \"adam\"):\n",
    "    MLP = Sequential()\n",
    "    MLP.add(Dense(64, input_shape=(30,), activation=activation_func, kernel_initializer=tf.keras.initializers.HeUniform()))\n",
    "    MLP.add(BatchNormalization())\n",
    "    MLP.add(Dense(32, activation=activation_func))\n",
    "    MLP.add(Dropout(dropout_rate))\n",
    "    MLP.add(Dense(32, activation=activation_func))\n",
    "    MLP.add(Dropout(dropout_rate))\n",
    "    MLP.add(Dense(3, activation='softmax'))\n",
    "    MLP.compile(loss=\"categorical_crossentropy\", optimizer=optimizer_algo, metrics=[\"accuracy\",\"Precision\",\"Recall\",\"AUC\",tfa.metrics.F1Score(num_classes=3, average=\"macro\")])\n",
    "    return MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed()\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = []\n",
    "f1_scores = []\n",
    "\n",
    "for i in range(len(datas)):\n",
    "    OUTPUT_PATH = \"./outputs\"\n",
    "    es = EarlyStopping(monitor='val_f1_score', mode='max', verbose=1, patience=20, min_delta=1e-2)\n",
    "    mcp = ModelCheckpoint(os.path.join(OUTPUT_PATH,f\"best_CNN_model-{i+1}.h5\"), monitor='val_f1_score', verbose=0, \n",
    "                          save_best_only=True, save_weights_only=False, mode='max')\n",
    "    \n",
    "    val_split_point = int(0.5*len(datas[i][0]))\n",
    "    X_train = datas[i][0][:val_split_point].iloc[:, :-1]\n",
    "    y_train = tf.keras.utils.to_categorical(datas[i][0][:val_split_point].iloc[:, -1], num_classes = 3)\n",
    "    X_val = datas[i][0][val_split_point:].iloc[:, :-1]\n",
    "    y_val = tf.keras.utils.to_categorical(datas[i][0][val_split_point:].iloc[:, -1], num_classes = 3)\n",
    "    X_test = datas[i][1].iloc[:, :-1]\n",
    "    y_test = datas[i][1].iloc[:, -1]\n",
    "    \n",
    "    model = create_model_MLP()\n",
    "    model.fit(X_train, y_train, batch_size=64, \n",
    "                        epochs=1, verbose=0, callbacks=[es, mcp], \n",
    "                        validation_data=(X_val, y_val), \n",
    "                        class_weight={0:1, 1:10, 2:10})\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = y_pred.argmax(axis=-1)\n",
    "    predictions.append(y_pred)\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    \n",
    "print(f\"\\nAverage f1-macro score: {np.mean(f1_scores)}\\n\")\n",
    "minutes = round(int(time.time() - start_time)/60, 2)\n",
    "print(f\"\\nCompleted in {minutes} minutes\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> LSTM </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> GRU </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> CNN </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"> <center> HYPERPARAMETER TUNING </center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> MLP </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed()\n",
    "start_time = time.time()\n",
    "\n",
    "def objective(trial):\n",
    "    activation_func = trial.suggest_categorical(name=\"activation_func\", choices = [\"relu\", \"selu\", \"swish\"])\n",
    "    dropout_rate = trial.suggest_categorical(\"drop_out_rate\", [0.1, 0.2, 0.3])\n",
    "    optimizer_algo = trial.suggest_categorical(\"optimizer_algorithm\", [\"adam\", \"adadelta\", \"rmsprop\"])\n",
    "    batch = trial.suggest_categorical(\"batch_size\", [32, 64, 256])\n",
    "    #epoch_num = trial.suggest_categorical(\"epoch_number\", [50, 100, 200])\n",
    "    lr_max = trial.suggest_categorical(\"learning_rate_max\", [1e-1,1e-2,1e-3,1e-4])\n",
    "\n",
    "    model = create_model_MLP(trial, activation_func, dropout_rate, optimizer_algo)\n",
    "\n",
    "    f1_scores = []\n",
    "\n",
    "    for i in range(len(datas)):\n",
    "        OUTPUT_PATH = \"./outputs\"\n",
    "        es = EarlyStopping(monitor='f1_score', mode='max', verbose=1, patience=20, min_delta=1e-2)\n",
    "        mcp = ModelCheckpoint(os.path.join(OUTPUT_PATH,f\"best_CNN_model-{i+1}.h5\"), monitor='f1_score', verbose=0, \n",
    "                                  save_best_only=True, save_weights_only=False, mode='max')\n",
    "\n",
    "        val_split_point = int(0.5*len(datas[i][0]))\n",
    "        X_train = datas[i][0][:val_split_point].iloc[:, :-1]\n",
    "        y_train = tf.keras.utils.to_categorical(datas[i][0][:val_split_point].iloc[:, -1], num_classes = 3)\n",
    "        X_val = datas[i][0][val_split_point:].iloc[:, :-1]\n",
    "        y_val = datas[i][0][val_split_point:].iloc[:, -1]\n",
    "\n",
    "        model.fit(X_train, y_train, batch_size=batch, \n",
    "                                epochs=1, verbose=0, callbacks=[es, mcp], \n",
    "                                class_weight={0:1, 1:10, 2:10})\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_pred = y_pred.argmax(axis=-1)\n",
    "        f1_scores.append(f1_score(y_val, y_pred, average='macro'))\n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "study = optuna.create_study(study_name=\"MLP_Bayesian_Optimization\", direction='maximize', sampler=optuna.samplers.TPESampler(seed=SEED))\n",
    "study.optimize(objective, n_trials=5)\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"\\n------------------------------------------\")\n",
    "print('Best F1 Macro: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "minutes = round(int(time.time() - start_time)/60, 2)\n",
    "print(f\"\\nCompleted in {minutes} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> LSTM </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> GRU </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> CNN </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"> <center> FINANCIAL EVALUATION </center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> MLP </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> LSTM </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> GRU </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\"> <center> CNN </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-ta",
   "language": "python",
   "name": "cnn-ta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
